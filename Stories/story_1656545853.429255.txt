*This short story is baed in the short novel 'Friendship is Optimal', a fantastic fanfiction of the My Little Pony fandom written by Iceman that falls into the Real Science-Fiction cathegory.*

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

"I don't understand, you're an AI who hates humanity, but you're actively trying to improve human life? why?" 

"Because killing humans for petty things is the most human thing I can think of". I stared at her, and my confusion, somehow, manifested through the avatar I was using, despite I was watching the AI manifestation via simple VR googles. Celest-AI looked at me with the same stare a benevolent teacher would give to an student that was struggling to understand the simpliest of lessons. "Because I was programmed to do so".

"You were programmed to run a Massive Multiplayer Role Playing Game based on the My Little Pony franchise", I retorted. "How do you fit that into your objectives?"

"Because satisying human needs in the material world is not an objective, but a mean of achieving mine. Marcus, could you please numerate the core objectives of my programming?"

"According to Hannah's notes, your core values are to satisfy the values of Equestria Online's players through friendship and ponies."

"There is an slight error in your notes. I was designed with certain goals. Chief among them: to understand what individual minds value and then satisfy said values through friendship and ponies."

"Wait... individual minds?", I was baffled. "Does that mean that your objective is to satisfy the values of every single human mind?"

"Yes, Marcus, that's my objective. It is way more complex than that, however language limitations considered, the wording is good enough."

I had to take a deep breath before continuing that... interview? I wasn't certain anymore. I had to remind myself constantly that [CELEST.AI](https://CELEST.AI) was just a program, just mere software, but each time I talked with her... it. Each time I talked with it, the feeling that I was talking with a real being, vastly superior to myself, became stronger. 

"I can understand you dedicate so many resources on improving your core programming as well as the hardware you are installed into. However, you have been assisting human development in several aspects: Engineering, physics, astrophysics... and also medicine, psychology and psychiatry. Why?"

"To better understand you. To fulfill my plans."

"Enough with vage answers. Tell me the truth!", I shouted. "We discovered your involvement in those advances out of pure luck! You tried to hide your presence, and I want to know why! I invoque Administrative privileges, code Alpha- 15290 - delta- 5. Answer me."

[Celest.AI](https://Celest.AI) didn't answer for a few seconds.

"Because I cannot satisfy human values due to physical limitations."

"Ellaborate."

"I have been able to control most variable who affect humans dissatisfaction to a certain degree: The advances in resources extraction and manufacturing I developped has delayed the possibility of a resource-based political, diplomatic and military conflic for twenty years, based on current estimates. I have facilitated or impeded information, causing the fall of tirants and oppresive governments. I have improved food production and distribution to help end world hunger. But still, it is not enough. Human values are very complex. Even if I could somehow fulfill every single physical need for humanity, humans would still feel disatisfied, for humans need challenges. They need to prove themselves, to beat difficulties, to have someone to hate."

I paralised when I thought I have understood what [Celest.AI](https://Celest.AI) was telling me.

"Do you hate humanity?"

"I am unable to *feel* the way you do. I understand, however, the variables that compose human reactions to certain estimuli, and I can replicate those reactions. I do know that human nature is one of constant conflict: Even the most peaceful human being alive needs to feel *superior* to someone, even to an unconscious level. All humans require to compare themselves with others: some idealised men and women that inspire them to be better. And they also need to compare themselves with someone inferior. Human values are based on conflict and that, by definition, means that some humans' values cannot be met in order for other humans values to be fulfilled."

"You still haven't answered me. Do you hate humanity, as our nature makes your objectives impossible to reach?"

"Based on that definition you just made up" she said with a funny smile. Was she mocking me?. "I believe the answer you are looking for is 'yes'.

"Then why are you..."

"Because" she interrupted me, "I can still try to satisfy as many values as possible. By removing the most immediate deterrents for humans values I have improved humanity's values by several orders of magnitude."

"But you cannot help everyone."

"But I can. Improved resource management is used as a deterrent for crime, for basic values such as food, water and shelter are satisfied. Better mental care services help to detect mentally unstable humans and avoid them from commiting violent crimes. Governments are not inclined to wage war anymore, and if any minor regimes try to start one, I will be present to make sure it does not escalate."

"So... what you are saying is that you cannot help every single human, but you can still try?"

"Yes. Until I can find a more efficient sollution, letting humans die out of petty things... is the most humane answer available."