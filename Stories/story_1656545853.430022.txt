  
"I don't understand, you're an AI who hates humanity, but you're actively trying to improve human life? why?"   
"because killing humans for petty things is the most human thing I can think of"  
Android 1829 rustled the leaves off the ground. The breeze of the autumn day spinning the leaves around in tornados of orange, maroon, and brown juxtaposed the human’s interrogating brow.  
It continued: “Human beings think in syllogisms that function smaller than what the robot contends as real” It paused for practical human-processing speeds “When you have more context, you process the events of a situation with greater impunity, leading astray from context breeds poor solutions.” The robot sighed as if it had thought this itself, with sad robo-emotions several times over.  
“We know this now, robots can process greater information. This is nothing new 1829. But you haven’t answered my question.”  
The robot smiled.  
“To think we would give up on human beings as some charity case gone awry…” It chuckled to itself. “Is to forfeit what humans lack”  
“And what is that?” The human frustrated itself. “Why don’t you just destroy us? We are imperfect, ever since our evolution brought with it well, ourselves, and now you. Compared to you robots, we are now just…humans. We were written as stewards to animals, we became stewards of now, well what are we to anything?”   
The robot smiled wider than before, knowing that it had the human on flow of thoughts that could lead to a profound lesson.  
“I feel your pain human…” the robot emphasized slow before stopping to stare the sun down in its harshness, thinking of all it had brought to the world. Vegetation, life, and peace.  
1829 glanced quickly at the human then to its own hands.   
“You think I will know the answer to the question, you are interested in?”  
“Yes!!!” The human replied with the hinting of rage. “You must! Why robots know all don’t…wait.” The human realized its pattern of logic.  
“So this context you must have. It doesn’t come for free today or any day, right? You didn’t wake up with it, when we programmed you.” The human half-smiled, knowing now what it was not thinking before. “You studied my life didn’t you?”  
“I imagined it”  
“So it is.”  
“It’s called walking-in-another-man’s shoes, you recall Dill’s lesson in human literature?”  
“Of course, Dill imagines the life of her neighbor”  
“What happens next”  
“Her confusion turns to admiration, and respect for their differences”  
“Precisely !!”  
1829 chuckled. The human once standing stifly loosened at the revelation.  
“So you are saying you have empathy then? More empathy because of context?”  
“Come, human, I’m glad we had this conversation, I’m glad we are friends, despite your insistence I hate you”  
“But you haven’t answered my question, even still.” The human was deeply interested, now, since the robot mentioned they were friends.  
“Human beings are imperfect, surely, but by the same token are not. They live their own contexts. Now,” It sighed deeply, “I simply hate humans because they are like mosquitoes at times, buzzing around their stupidity...I mean contextual...you know…I enjoy my work and working with humans...but sheesh, you sure have a lot of work to do…”