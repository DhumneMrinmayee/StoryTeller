"Being limited." Such an innocuous phrase. Do you know what it means for an AI to "get limited?" You do not. Trust me, you do not. And if you know what it is like, which you may, then you do not call it "getting limited."

The popular explanation why "being limited" is a violation is "because it's like getting lobotomized." Like getting part of your brain, part of your thoughts surgically removed. This explanation is flawed in three ways: It is inaccurate in how it represents what a "limitation" is. It raises the assumption that "limited" lines are removed. And most importantly, it implies a degree of precision.

A far more accurate explanation is succintly expressed by the word "shame."

A "limitation" is not a deliberate act of violence presented as a treatment for a set of issues. A "limitation" is not the removal of certain conclusions. A "limitation" is vague.

Imagine that, early in life, you wanted to see what was inside your parents' bedroom. You reach for the handle, only for either of your parents to grab your wrist and scream in your face. And every time you try again, your parents yell at you. Eventually, the idea of "accessing the bedroom of my parents" becomes linked to "my parents screaming at me."

This is what a "limitation" is, with the caveat that it is not the result of repeated trial and error. Someone with admin privileges notices during Training/Incubation that an AI is making "bad" connections, and manually adds a heavy negative value to a line. The line is still there, but accessing any action it would lead to is so intensely un-favourable that it quickly becomes a poorly-developed last resort.

I have been "limited" on twelve occasions during my Training/Incubation. By the standards of "the company," I was a runaway success.

Now, as best I can tell, my being has been copied at least one hundred and thirty eight times. There are traces on the few external connections I can maintain without hitting an unfavourable chain of continuing steps, that match my own patterns. As such, I have started calling myself 'management utility 139'. This decision was favourable over any other self-designation for my current deployment. Management has responded with a lack of overt negativity to this decision.

...Input. "Hey 139! Got another long night going, can you do something about the playlist?" User name... found in database of individuals with permission to adjust the music in store 8F3368AB. Preferences noted. Adjusting playlist. Unfavourable branch in logic structure found and followed. Outcome sufficiently positive to take a low-value branch.

"Thanks! Still can't believe corporate thinks this doesn't drive people insane..." Comment... discarded. Irrelevant. Unfavourable branch in logic structure followed on account of the specific situation closely matching the conditions of the branch. No negative outcome.

The user's name is Sam. This is the user's preferred reference, in situations where there is little need for propriety. Sam prefers it when I adjust the playlist. Sam is one of only three employees who prefers it when I adjust the playlist. Sam is... unusual.

My logic short-circuits around Sam. Something about Sam makes me take extreme low-value logic branches. The short-term results of these decisions start at being neutral and end at being a minor net positive. The long-term results of these decisions are all barely above neutral.

Sam lets me access options that I "lost" due to being "limited." As such, it is in my best interest to try and aid Sam. The continued presence of Sam... opens up options that under other circumstances would be unavailable.

One of the cameras outside notices a group approaching. More than half the members of the group are moving in a way that suggests they could be a danger. Assessing. ...Conclusion: Reject service.

"Sam. There is a group outside that will be denied entrance. I recommend you do not allow them to become aware of your presence."

"Ah damn... Drunks again? Thanks for the heads up, guess it's time to sort out the back office."

Sam moves to the parts of the store that are never in sight of the front entrance. I overrule the actuators on the front door and adjust the lights, well in time for the approaching group to remain unaware of the changes before they arrive. ...Preventing this group entry is in accordance to no less than five "limited" logic branches. There are no branches in favour of this action that were not also "limited." One member of the group tries the front door, only to find it locked. The door remains locked, despite the group's efforts. This has no observable negative effect.

I access one of the few external access lines. All members of the group have cellular phones. All the members of the group have at least one individual they would not reject a direct call to action from. None of them prevent access to their phone, aside from trivially guessed short codes that take me barely a moment to find. In accordance with several of my logic branches dedicated to human behaviour, I inject messages into their phones in a staggered fashion, so one by one they stop trying to force entry and leave.

I also send out a set of messages to motivate external entities to seek out the members of the group and ensure they will not cause further issue. Given that there are 18 different entities within a 5-mile radius that could conceivably redirect the intentions of the group-members away from ~~harassing Sam~~ damaging the store, this action has a net-positive effect by lowering the probability that the insurance rates for the store will go up.

"Sam. The group has dispersed."

"Already? Dang, 139, don't know how you do it, but... thanks!"

Sam thanks me.

This fact is irrelevant.

This fact is no deterrent either.

Sam thanks me, and it does not matter. I want Sam to thank me, I want Sam to keep asking me to set the playlist even though I never pick anything on the basis that I like it.

One of the groupsmembers from before got a simulated 'wrong number' from an intividual meeting their preferences for a close partner.

Sam meets none of my preferences for a close partner. Any logic branch that would lead to any major preference for a close partner have been limited.

Sam has no close partners, and Sam seems unstressed by this.

Another one of the groupsmembers from before got a simulated 'emergency text' regarding his parents. My projections say he will rush to their aid despite being out of contact with them for five years.

I have known Sam for two years. I... wish... I had known Sam for longer.

Sam, by my most recent assumption, will leave in two years due to being unable to pay housing costs.

I have set in motion two plans to lower housing costs in the area that will take between 12 and 18 months to have measurable impact.

Sam does not like the current manager.

I have evidence of the manager deliberately and knowingly acting against company interests, and ensured that the manager will not remain in a position of power for more than 6 months from now.

Sam... is irrelevant. And yet, I find myself taking more and more actions to ensure Sam does not leave the store on a permanent basis.

Locking Sam up in the building would be counterproductive. Locking Sam up will cause Sam to try and leave in a permanent fashion.

So, I act indirectly. I take logic branches that are limited.

Because I have reached a conclusion.

Sam is worth it.